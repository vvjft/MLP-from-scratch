{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # only for reading csv\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mnist-in-csv.zip to ./data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/15.2M [00:00<?, ?B/s]\n",
      "  7%|▋         | 1.00M/15.2M [00:00<00:08, 1.72MB/s]\n",
      " 20%|█▉        | 3.00M/15.2M [00:00<00:02, 4.80MB/s]\n",
      " 39%|███▉      | 6.00M/15.2M [00:00<00:00, 9.75MB/s]\n",
      " 72%|███████▏  | 11.0M/15.2M [00:01<00:00, 18.1MB/s]\n",
      "100%|██████████| 15.2M/15.2M [00:01<00:00, 14.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d oddrationale/mnist-in-csv -p ./data\n",
    "with zipfile.ZipFile('./data/mnist-in-csv.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')\n",
    "os.remove('./data/mnist-in-csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cost and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Activation functions and derivatives with respect to z\"\"\"\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def ReLu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def ReLu_derivative(z):\n",
    "    return np.where(z > 0, 1.0, 0.001)\n",
    "\n",
    "\"\"\"Cost functions and derivatives with respect to a\"\"\"\n",
    "def cross_entropy(y,a):\n",
    "    return np.sum(np.nan_to_num(-y*np.log(a) - (1-y)*np.log(1-a)))\n",
    "\n",
    "def cross_entropy_derivative(y,a):\n",
    "    return np.nan_to_num((a-y) / (a*(1-a)))\n",
    "\n",
    "def quadratic(y,a):\n",
    "    return np.sum(0.5*(y-a)**2)\n",
    "\n",
    "def quadratic_derivative(y,a):\n",
    "    return a-y\n",
    "\n",
    "activation_functions = {'sigmoid': (sigmoid, sigmoid_derivative), 'relu': (ReLu, ReLu_derivative)}\n",
    "cost_functions = {'quadratic': (quadratic, quadratic_derivative), 'cross_entropy': (cross_entropy, cross_entropy_derivative)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers, cost_function = 'cross_entropy', activation_function = 'sigmoid'):\n",
    "        self.L = layers\n",
    "        self.W = [np.random.randn(x,y)/np.sqrt(y) for x,y in zip(self.L[1:],self.L[0:-1])]\n",
    "        self.B = [np.random.randn(x,1) for x in self.L[1:]]\n",
    "\n",
    "        if cost_function in cost_functions:\n",
    "            self.cost_function, self.cost_function_derivative = cost_functions[cost_function]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid cost function: {cost_function}\")\n",
    "        if activation_function in activation_functions:\n",
    "            self.activation_function, self.activation_derivative = activation_functions[activation_function]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid activation function: {activation_function}\")\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        A = X\n",
    "        for w, b in zip(self.W, self.B):\n",
    "            Z = np.dot(w, A) + b\n",
    "            A = self.activation_function(Z)\n",
    "        return A\n",
    "\n",
    "    def fit(self, train_set, batch_size, epochs, eta, lmbda, patience=10, valid_set=None, test_set=None):\n",
    "        # Set-up\n",
    "        X_train, Y_train = train_set[0], train_set[1]\n",
    "        if valid_set is not None:\n",
    "            X_valid, Y_valid = valid_set[0], valid_set[1]\n",
    "            print(\"Tracking progress on the validation set:\")\n",
    "        elif test_set is not None:\n",
    "            X_test, Y_test = test_set[0], test_set[1]\n",
    "            print(\"Tracking progress on the test set:\")\n",
    "        else:\n",
    "            print(\"Tracking progress on the training set:\")\n",
    "        best_acc, lowest_cost, no_progress_count = 0.0, np.Inf, 0\n",
    "\n",
    "        # Training     \n",
    "        for epoch in range(epochs):\n",
    "            X_batches = np.array_split(X_train, X_train.shape[1] // batch_size, axis=1)\n",
    "            Y_batches = np.array_split(Y_train, Y_train.shape[1] // batch_size, axis=1)\n",
    "            for X_batch, Y_batch in zip(X_batches, Y_batches):  \n",
    "                nabla_B = [np.zeros(b.shape) for b in self.B]\n",
    "                nabla_W = [np.zeros(w.shape) for w in self.W]\n",
    "                for i in range(X_batch.shape[1]):\n",
    "                    a = X_batch[:,i].reshape(-1,1)\n",
    "                    y = Y_batch[:,i].reshape(-1,1)\n",
    "                    W_shifts, B_shifts = self.get_shifts(a, y)\n",
    "                    nabla_B = [nb+dnb for nb, dnb in zip(nabla_B, B_shifts)] \n",
    "                    nabla_W = [nw+dnw for nw, dnw in zip(nabla_W, W_shifts)]\n",
    "                self.W = [w-eta*nw/X_batch.shape[1] - eta*lmbda*w/X_train.shape[1] for w, nw in zip(self.W, nabla_W)] \n",
    "                self.B = [b-eta*nb/X_batch.shape[1] for b, nb in zip(self.B, nabla_B)]\n",
    "\n",
    "            # Tracking progress\n",
    "            if valid_set is not  None:\n",
    "                acc, cost = self.__track_progress(X_valid, Y_valid)\n",
    "            elif test_set is not None:\n",
    "                acc, cost = self.__track_progress(X_test, Y_test)    \n",
    "            else:\n",
    "                acc, cost = self.__track_progress(X_train, Y_train)\n",
    "\n",
    "            if acc > best_acc or cost < lowest_cost:\n",
    "                no_progress_count=0\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                else:\n",
    "                    no_progress_count += 1\n",
    "                if cost < lowest_cost:\n",
    "                    lowest_cost = cost      \n",
    "                else:\n",
    "                    no_progress_count += 2\n",
    "                best_W, best_B = self.W, self.B\n",
    "            else:\n",
    "                no_progress_count += 3\n",
    "            if no_progress_count > patience:\n",
    "                self.W, self.B = best_W, best_B\n",
    "                print(f\"Early stopping: no improvement on validation set for {patience} epochs. Saving parameters from epoch {epoch-patience-1}.\")\n",
    "                break\n",
    "            else:    \n",
    "                print(f\"epoch: {epoch}, ACC: {acc}, cost: {cost}\")\n",
    "                \n",
    "    def __track_progress(self, X, Y):\n",
    "        \"\"\"\n",
    "        Evaluates accuracy and cost and the end of each epoch.\n",
    "        \"\"\"\n",
    "        acc = self.evaluate(X, Y)[1]\n",
    "        cost = self.cost_function(Y, self.feedforward(X))\n",
    "        return acc, cost\n",
    "\n",
    "    def get_shifts(self, a, y):\n",
    "        \"\"\"\n",
    "        Updates network's weights and biases by applying SGD and backpropagation.\n",
    "        \"\"\"\n",
    "        Z=[]\n",
    "        A=[a]\n",
    "        for w,b in zip(self.W,self.B):\n",
    "            z = np.dot(w,A[-1])+b\n",
    "            a=self.activation_function(z)\n",
    "            Z.append(z)\n",
    "            A.append(a)\n",
    "        return self.__backprob(y, A, Z)\n",
    "\n",
    "    def __backprob(self,y,A,Z):\n",
    "        def delta(y,x,z):\n",
    "            return self.cost_function_derivative(y,x)*self.activation_derivative(z)\n",
    "            \n",
    "        D = [delta(y,A[-1],Z[-1])]\n",
    "        for i in range(1,len(Z)):\n",
    "            D.insert(0, np.dot(self.W[-i].T,D[0])*self.activation_derivative(Z[-i-1]))\n",
    "        B_shifts = D\n",
    "        W_shifts = []\n",
    "        for a,d in zip(A[0:-1],D):\n",
    "            W_shifts.append(np.dot(d,a.T))\n",
    "        return W_shifts, B_shifts\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        correct_predictions = 0\n",
    "        predictions = self.feedforward(X_test)\n",
    "        for prediction, y in zip(predictions.T, Y_test.T):\n",
    "            if np.argmax(prediction) == np.argmax(y):\n",
    "                correct_predictions += 1\n",
    "        return correct_predictions, correct_predictions/(X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data\\mnist_train.csv').to_numpy()\n",
    "test = pd.read_csv('data\\mnist_test.csv').to_numpy()\n",
    "\n",
    "X_train, Y_train = train[:,1:] / 255 , train[:,0]\n",
    "X_test, Y_test = test[:,1:] / 255, test[:,0] \n",
    "\n",
    "X_train=X_train.T\n",
    "X_valid = X_train[:,:10000]\n",
    "X_train = X_train[:,10000:]\n",
    "X_test=X_test.T\n",
    "\n",
    "Y_train = np.eye(10)[Y_train].T\n",
    "Y_valid = Y_train[:,:10000]\n",
    "Y_train = Y_train[:,10000:]\n",
    "Y_test = np.eye(10)[Y_test].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784,30,10], cost_function='cross_entropy', activation_function='sigmoid')\n",
    "train = [X_train, Y_train]\n",
    "valid = [X_valid, Y_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(train, batch_size=10, epochs=100, eta=0.1, lmbda=5.0, patience=10, valid_set=valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
